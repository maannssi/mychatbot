# GPT Clone Chatbot ğŸ¤–

A modern, multi-chat, file-uploading chatbot UI built with [Streamlit](https://streamlit.io/) and [LangChain](https://python.langchain.com/), powered by [OpenRouter](https://openrouter.ai/) (OpenAI-compatible API).  
Supports PDF & image upload per chat, chat history, and a ChatGPT-like interface.

---

## ğŸ¯ Features

- **ChatGPT-style UI** with multi-chat sidebar (create, rename, delete chats)
- **LLM Integration** via LangChain's unified factory (supports 20+ providers)
- **OpenRouter API** for cost-effective LLM responses (Mistral 7B by default)
- **PDF & Image Upload** support per chat session
- **Chat History** with persistent session state
- **Message Management** with automatic conversation context handling

---

## ğŸ› ï¸ Tech Stack

### **Core Technologies**

| Technology | Purpose | Why Used |
|------------|---------|----------|
| **Streamlit** | Web UI Framework | No HTML/CSS needed; Python-only, rapid prototyping |
| **LangChain** | LLM Orchestration | Unified interface for 20+ LLM providers, conversation management |
| **OpenRouter API** | LLM API Provider | Cost-effective, supports multiple models, OpenAI-compatible |
| **Mistral 7B** | Language Model | Fast, lightweight, good for chat at low cost |
| **Python 3.12** | Runtime | Modern async support, type hints |

### **Supporting Libraries**

- **langchain-core** â€“ Core message types (AIMessage, HumanMessage)
- **langchain-openai** â€“ OpenAI-compatible provider integration
- **python-dotenv** â€“ Environment variable management
- **PyPDF2** â€“ PDF text extraction
- **Pillow** â€“ Image handling

---

## ğŸ“š How It Works

### **Architecture Overview**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Streamlit Web UI (main.py)        â”‚
â”‚  - Chat display                     â”‚
â”‚  - File uploads                     â”‚
â”‚  - Session state management         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â”œâ”€ calls init_chat_model()
             â”‚
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   LangChain (langchain.chat_models) â”‚
â”‚  - Unified LLM interface            â”‚
â”‚  - Message routing                  â”‚
â”‚  - Provider detection               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â”œâ”€ maps to openai provider
             â”‚
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   OpenRouter API Proxy              â”‚
â”‚   https://openrouter.ai/api/v1      â”‚
â”‚  - Cost optimization                â”‚
â”‚  - Model routing                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Mistral 7B LLM                    â”‚
â”‚  (or any other model you choose)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **User Interaction Flow**

1. **User Types Message** â†’ Streamlit captures input
2. **Append to History** â†’ Message added as `HumanMessage`
3. **Initialize LLM** â†’ LangChain creates model instance via `init_chat_model()`
4. **Send to API** â†’ Full conversation history sent to Mistral 7B
5. **Get Response** â†’ AI response received and appended as `AIMessage`
6. **Display in UI** â†’ Streamlit renders response in chat bubble
7. **Persist State** â†’ Conversation saved in `st.session_state`

### **Key Components Explained**

#### **main.py** (Core App Logic)
- Initializes Streamlit UI with `st.set_page_config()`
- Manages chat sessions using `st.session_state` (persists across reruns)
- Creates sidebar with chat list and controls
- Displays message history with `st.chat_message()`
- Handles user input via `st.chat_input()`
- Initializes LLM using `init_chat_model()` from LangChain

#### **file_uploads.py** (File Handling)
- `handle_pdf_upload()` â€“ Uploads PDF, extracts text, appends to chat
- `handle_image_upload()` â€“ Uploads images, displays preview, logs metadata

#### **LangChain's `init_chat_model()`**
Instead of provider-specific imports (old way):
```python
# âŒ Old (provider-specific)
from langchain_openai import ChatOpenAI
chat = ChatOpenAI(model="gpt-4")

# âœ… New (unified factory)
from langchain.chat_models import init_chat_model
chat = init_chat_model(
    model="mistralai/mistral-7b-instruct",
    model_provider="openai",
    openai_api_base="https://openrouter.ai/api/v1",
    openai_api_key=api_key,
)
```

**Benefits:**
- Single interface for all providers
- Easy model/provider switching
- Automatic API routing
- Built-in retry logic

#### **Streamlit Session State**
```python
st.session_state.chat_sessions = {
    "Chat 1": [AIMessage(...), HumanMessage(...), ...],
    "Chat 2": [AIMessage(...), ...],
}
```
- Persists data across page reruns
- Triggered by button clicks, input changes
- No database needed for session management

---

## ğŸš€ Changing Models

Edit the `model` and `model_provider` in `main.py` (around line 95):

### **Use GPT-4o**
```python
chat = init_chat_model(
    model="openai/gpt-4o",
    model_provider="openai",
    openai_api_key=api_key,
)
```

### **Use Claude 3.5 Sonnet**
```python
chat = init_chat_model(
    model="anthropic/claude-3-5-sonnet-20241022",
    model_provider="anthropic",
    anthropic_api_key=api_key,
)
```

### **Use Llama 2 70B via OpenRouter**
```python
chat = init_chat_model(
    model="meta-llama/llama-2-70b-chat",
    model_provider="openai",
    openai_api_base="https://openrouter.ai/api/v1",
    openai_api_key=api_key,
)
```

See all available models at: https://openrouter.ai/models

---

## ğŸ“¦ Getting Started

### **1. Clone the repository**

```bash
git clone https://github.com/maannssi/mychatbot.git
cd mychatbot
```

### **2. Create and activate a virtual environment**

```bash
# Windows
python -m venv .venv
.venv\Scripts\Activate.ps1

# Mac/Linux
python -m venv .venv
source .venv/bin/activate
```

### **3. Install dependencies**

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

**Required packages:**
- `streamlit` â€“ Web UI
- `langchain` â€“ LLM orchestration  
- `langchain-core` â€“ Message types
- `langchain-openai` â€“ OpenAI-compatible provider
- `python-dotenv` â€“ Load environment variables
- `PyPDF2` â€“ PDF text extraction
- `Pillow` â€“ Image handling
- `openai` â€“ OpenRouter client

### **4. Set up your API key**

1. Get a free API key from [OpenRouter](https://openrouter.ai/) (includes free credits)
2. Create a `.env` file in your project root:

```env
OPENROUTER_API_KEY=sk-or-your-openrouter-key-here
```

3. **Important:** Add `.env` to `.gitignore` (never commit API keys!)

```bash
echo ".env" >> .gitignore
```

---

## ğŸ® Usage

```bash
streamlit run main.py
```

The app opens at `http://localhost:8501`

**How to use:**
1. **Sidebar Controls:**
   - â• **New Chat** â€“ Create a new conversation
   - Click a chat name to switch between them
   - âœï¸ **Rename** â€“ Change chat title
   - ğŸ—‘ï¸ **Delete** â€“ Remove chat

2. **Chat Area:**
   - Type a message at the bottom
   - AI responds with Mistral 7B (or your chosen model)
   - All messages stored in session

3. **File Uploads:**
   - Upload PDFs â€“ text extracted and added to context
   - Upload images â€“ preview displayed

---

## ğŸ“‚ Project Structure

```
mychatbot/
â”‚
â”œâ”€â”€ main.py                    # Main Streamlit app
â”‚   â”œâ”€â”€ UI setup
â”‚   â”œâ”€â”€ Session state management
â”‚   â”œâ”€â”€ Chat logic
â”‚   â””â”€â”€ LLM initialization (init_chat_model)
â”‚
â”œâ”€â”€ file_uploads.py            # File handling utilities
â”‚   â”œâ”€â”€ handle_pdf_upload()
â”‚   â””â”€â”€ handle_image_upload()
â”‚
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ .env                       # API key (NOT committed)
â”œâ”€â”€ .gitignore                 # Excludes .env, __pycache__, .venv
â””â”€â”€ README.md                  # This file
```

---

## ğŸ”§ Customization

### **Change the LLM Model**

Edit lines 95-102 in `main.py`:

```python
chat = init_chat_model(
    model="mistralai/mistral-7b-instruct",      # â† Change this
    model_provider="openai",                     # â† And/or this
    openai_api_base="https://openrouter.ai/api/v1",
    openai_api_key=api_key,
)
```

### **Adjust UI Layout**

- Change sidebar width, colors, or fonts
- Customize chat bubble styling
- Add new Streamlit components (charts, tables, etc.)

### **Add New Features**

Examples:
- **Conversation memory summarization** â€“ Compress old messages to save tokens
- **Conversation search** â€“ Search through all past chats
- **Export conversations** â€“ Save as PDF or TXT
- **Custom system prompts** â€“ Give the AI specific instructions
- **Tool calling** â€“ Let the LLM use external tools (search, calculator, etc.)

---
<img width="1918" height="951" alt="image" src="https://github.com/user-attachments/assets/d6f219ec-6292-4842-a5c9-27998c9d03b5" />


## ğŸ› Troubleshooting

**Issue:** `ModuleNotFoundError: No module named 'langchain.schema'`
- **Fix:** Uses `langchain_core.messages` (updated in recent versions)

**Issue:** `ImportError: cannot import name 'ChatOpenAI'`
- **Fix:** Use `init_chat_model()` from `langchain.chat_models` instead

**Issue:** API calls failing with 401 Unauthorized
- **Fix:** Check your `OPENROUTER_API_KEY` in `.env` file

**Issue:** Streamlit not finding the app
- **Fix:** Make sure you're in the project folder and run `streamlit run main.py`

---

## ğŸ“Š Model Comparison

| Model | Provider | Speed | Quality | Cost | Best For |
|-------|----------|-------|---------|------|----------|
| Mistral 7B | OpenRouter | âš¡ Fast | ğŸŸ¡ Good | ğŸ’° Cheap | **Current setup** |
| GPT-4o | OpenAI | ğŸŒ Slow | ğŸŸ¢ Excellent | ğŸ’°ğŸ’°ğŸ’° Expensive | Complex tasks |
| Claude 3.5 | Anthropic | ğŸš— Medium | ğŸŸ¢ Excellent | ğŸ’°ğŸ’° Medium | Writing, analysis |
| Llama 2 70B | OpenRouter | ğŸŒ Slow | ğŸŸ¡ Good | ğŸ’° Cheap | Open-source alternative |
| Gemini 2.5 | Google | âš¡ Fast | ğŸŸ¢ Excellent | ğŸ’°ğŸ’° Medium | Balanced, multimodal |

---

## ğŸ“š Learning Resources

- **Streamlit Docs:** https://docs.streamlit.io/
- **LangChain Docs:** https://python.langchain.com/
- **OpenRouter Models:** https://openrouter.ai/models
- **LangChain Chat Models:** https://python.langchain.com/docs/integrations/chat/

---

## ğŸ“„ License

MIT License â€“ Feel free to use and modify!

---

## ğŸ™ Credits

- **[Streamlit](https://streamlit.io/)** â€“ Web UI framework
- **[LangChain](https://python.langchain.com/)** â€“ LLM orchestration
- **[OpenRouter](https://openrouter.ai/)** â€“ LLM API provider
- **[Mistral AI](https://mistral.ai/)** â€“ Open-source LLM
